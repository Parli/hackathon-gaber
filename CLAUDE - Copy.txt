# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Overview of the starting conditions

Node Simple Server is a minimalistic vanilla Node.js TypeScript server for rapid prototyping. It provides:

- Static file serving from the `public` directory
- Persistent storage API through `/api/store/` endpoints
- External service proxy via `/api/proxy/` with environment variable interpolation
- Frontend example integrating with various AI providers (OpenAI, Anthropic, Google)

## Commands

### Development

- **Start the server in development mode**: `npm run dev`
  - This loads environment variables from `.env` file

### Deployment

- **Deploy to Google Cloud Run**: `npm run deploy`
  - Creates/updates a Cloud Run service named after the project directory
  - Configures environment variables, secrets, and storage buckets
  - Uses Google Cloud's source-based deployment

- **Remove Cloud Run deployment**: `npm run undeploy`
  - Deletes the Cloud Run service

### Environment Setup

- **Initialize environment variables from 1Password**: `op inject -i example.env -o .env`
  - Required before first run

## Architecture

### Server (server.ts)

- HTTP server handling routes for static files, storage, and proxy requests
- Uses vanilla Node.js modules (http, fs, path, crypto) without external dependencies
- Environment variables:
  - `STORAGE_LOCATION`: Custom location for the storage file (default: `./storage`)
  - API keys and access permissions for proxy requests (see `example.env`)

### Storage

- Simple JSON-based persistence for storing arbitrary strings
- Uses MD5 hashing to generate URL-safe storage IDs
- File-based storage that can be backed by a mounted cloud bucket in production

### Proxy

- Forwards requests to external services with environment variable interpolation
- Security features:
  - Each environment variable requires a corresponding `*_ACCESS` variable
  - Allows whitelisting of specific hostnames for variable access

### Frontend (public/index.html, public/main.js)

- Simple demo integrating with multiple AI providers
- Uses Vercel AI SDK for streaming responses
- Supports sharing conversations via storage API
- Uses CDN-hosted libraries:
  - Vercel AI SDK and providers
  - Marked (Markdown parser)
  - Morphdom (DOM diffing)

## Development Flow

1. Initialize environment (requires 1Password): `op inject -i example.env -o .env`
2. Start the development server: `npm run dev`
3. Access the application at http://localhost:8080
4. Make changes to server.ts or public files
5. Restart the server to apply changes

## Deployment Flow

1. Create/update the Cloud Run service: `npm run deploy`
2. To remove the deployment: `npm run undeploy`

---

# Home Remodeling Visualization Tool

## Project Overview

This project is building an AI-powered tool that helps users visualize home remodeling with products they can actually purchase online. The system uses Gemini's vision AI to analyze a user's room photo, generate realistic visualizations of the remodeled space, and facilitate the purchase of those products.

## Core Requirements

- **CRITICAL**: Use ONLY the "gemini-2.0-flash-preview-image-generation" model
- Focus on a conversational UI similar to the existing demo
- Include file upload for room photos
- Display both original room photo and progressively modified versions side-by-side
- Include brief instructions with example queries for room redecoration
- Handle transitions between stages conversationally, not with specific UI elements
- Implement simple error handling for cases when Gemini doesn't return images
- Store conversation and images in memory (no need for persistence)

## User Flow

1. **Photo Upload**: User uploads a photo of their room with optional notes about desired changes
2. **Initial Analysis**: Send to Gemini for analysis of the current room
3. **Visualization Creation**: Generate remodeled room with placeholder items
4. **Refinement Conversation**: Enable back-and-forth to modify room and placeholder products
5. **Product Matching**: Call external API (to be provided later) to find real products similar to placeholders
6. **Product Visualization**: Feed real product images back to Gemini to replace placeholders in the visualization
7. **Display Final Result**: Show the remodeled room with real products

## Technical Implementation

### UI Requirements

- Remove the provider selection dropdown - only use Gemini
- Display both original and current modified images side-by-side
- Include brief instructions with one example query
- Implement file upload component for room photos
- Error handling for when Gemini fails to return images

### Gemini Integration

```javascript
// Always use this specific model
const model = "gemini-2.0-flash-preview-image-generation";

// Always include response_modalities for images
const config = {
  response_modalities: ['TEXT', 'IMAGE']
};
```

### Image Handling Flow

1. User uploads room photo
2. Store original photo in memory for reference
3. Send to Gemini with user's initial description of desired changes
4. Receive and display both text feedback and modified room image
5. Support continued conversation for refinements
6. When ready, transition to product matching (details to be implemented later)

### Error Handling

- Implement basic error messages if Gemini doesn't return images
- No need to handle file size limitations (under 20MB assumption)

## Implementation Notes

- The LLM will identify replaceable items based on conversation context
- Preference is to keep the UI simple initially, focusing on core functionality
- Start with in-memory storage of images and conversation history
- No need for special handling of the 20MB file size threshold

## Implementation Progress

### Current Status
We have successfully implemented:

1. A completely redesigned UI featuring:
   - Side-by-side display of original and modified room images
   - File upload functionality for room photos
   - Conversational interface for describing desired changes
   - Error handling and logging

2. Direct integration with Gemini's image generation model:
   - Successfully connected to the `gemini-2.0-flash-preview-image-generation` model
   - Built a secure API key handling system via a dedicated server endpoint
   - Implemented proper image encoding/decoding for API requests and responses

### Gemini Image Generation Integration Details

Working with the `gemini-2.0-flash-preview-image-generation` model required several specific configurations:

#### API Request Format
The correct format for image generation requests:
```javascript
{
  contents: [{
    parts: [
      // Add system prompt to the beginning of user message
      { text: systemPrompt + "\n\n" },
      // Include the image part
      { 
        inline_data: {
          mime_type: "image/jpeg", // or whatever the image format is
          data: base64EncodedImage 
        }
      },
      // User's query text
      { text: userQuery },
      // Explicit request for image in response
      { text: "\nPlease include an image in your response showing the remodeled room." }
    ],
    role: "user"  // Only 'user' and 'model' roles are supported
  }],
  generationConfig: {
    temperature: 0.4,
    topK: 32,
    topP: 0.95,
    responseModalities: ['TEXT', 'IMAGE']  // Must include both TEXT and IMAGE
  }
}
```

#### Key Requirements

1. **Role restrictions**: Only `user` and `model` roles are supported, not `system`. System prompts must be included in the user message.

2. **Response modalities**: Must explicitly request both `TEXT` and `IMAGE` in the response modalities.

3. **Direct image requests**: Include explicit instructions in the prompt to generate and include images.

4. **Image formatting**: Base64-encoded images must be properly formatted with correct MIME types.

5. **Response parsing**: Images are returned in the `inline_data` field of response parts, and must be properly extracted and decoded.

### Next Steps

The next phase will involve:

1. Continuing the conversational refinement process through multiple turns
2. Implementing the API integration to find real products matching the placeholders 
3. Feeding those product images back to Gemini to incorporate them into the visualization
4. Enabling the sharing and saving of final designs

## Update Log

### May 22, 2024 - Advanced Context Handling and Image Input Enhancements

1. **LLM-Powered Context Awareness**:
   - Implemented full conversation history with images in API requests
   - Enabled natural language references to previous designs without hardcoding
   - Added image memory with up to 5 previous conversation turns
   - Optimized conversation format for Gemini API compatibility
   - Improved prompt handling to maintain contextual awareness across turns

2. **Inline Image Attachments**:
   - Added clipboard image pasting directly into chat messages
   - Implemented drag-and-drop support for adding images to messages
   - Created visual indicators and previews for attached images
   - Added ability to remove pasted images before sending
   - Enhanced message display to show attached images inline

3. **Original Image Handling**:
   - Implemented "reset to original" feature to restart designs from the original photo
   - Added natural language detection for requests to use the original image
   - Improved feedback when switching between original and modified images
   - Optimized image handling logic to maintain correct context

4. **Conversation Flow Refinements**:
   - Enhanced feedback messages for image processing states
   - Added visual indicators for messages with image attachments
   - Improved loading state handling for multiple operations
   - Simplified the UI by removing unnecessary buttons and controls

5. **Technical Improvements**:
   - Structured conversation history to properly handle both text and images
   - Implemented proper request formatting for multi-turn Gemini conversations
   - Added role mapping between internal and API roles (assistant ‚Üí model)
   - Enhanced base64 encoding/decoding for image handling
   - Optimized token usage by limiting history to recent exchanges

### May 21, 2024 - UI Polish and Core Functionality Enhancements

1. **Interface Refinements**:
   - Simplified UI by removing the provider selection dropdown
   - Optimized layout for better screen space utilization (7:5 ratio for chat:image columns)
   - Improved visual hierarchy with consistent styling and color variables
   - Added responsive design adjustments for different screen sizes
   - Enhanced scrollbar styling for a more polished look

2. **Image Handling Improvements**:
   - Implemented toggle control to show/hide the original image
   - Added support for showing up to 3 most recent remodeled versions
   - Enhanced image display container with clearer labeling
   - Improved progressive visualization by using the latest modified image for new requests
   - Better error recovery when image generation fails

3. **Conversation Experience**:
   - Enhanced markdown parsing for AI responses
   - Improved loading states during API requests with spinner animation
   - Better error handling with user-friendly messages
   - Added context-aware response handling

4. **System Improvements**:
   - Removed sharing functionality for simplification
   - Enhanced security in API key handling
   - Improved logging for better debugging
   - Optimized memory usage for image and conversation storage

5. **System Prompt Enhancement**:
   - Refined the AI system prompt for more contextual responses
   - Added intelligence to determine when image generation is appropriate
   - Improved instructions for maintaining room dimensions and layout

### May 20, 2024 - Initial UI and Gemini Integration

1. **HTML Interface & UI Improvements**:
   - Created a clean, user-friendly interface with a modern design
   - Implemented side-by-side image display for original and modified room photos
   - Added file upload functionality for room photos
   - Built a conversational interface for design requests and feedback
   - Enhanced the visual style with better spacing, shadows, and a consistent color scheme
   - Removed duplicate preview image section for cleaner design

2. **Gemini Model Integration**:
   - Successfully integrated with the `gemini-2.0-flash-preview-image-generation` model
   - Created a secure API key handling system via a dedicated server endpoint
   - Implemented proper image encoding/decoding for data transfer
   - Added error handling for API responses and user interactions

3. **Smart Response Handling**:
   - Implemented detection of text-only vs. design requests
   - Added ability to have text-only conversations without generating images
   - Improved response handling for both text and image responses
   - Enhanced error messaging for cases when image generation fails

4. **Technical Challenges Solved**:
   - Resolved issues with the Gemini API's response modalities requirements
   - Fixed problems with image formatting and API request structure
   - Addressed authentication requirements for the Gemini API
   - Implemented workarounds for the model's constraint of requiring both TEXT and IMAGE response modalities

5. **UI Refinements**:
   - Added loading indicators for better user experience
   - Improved message styling for clearer conversation flow
   - Enhanced form validation and error feedback
   - Added sharing functionality for completed designs

### May 23, 2024 - Major UX Improvements and Workflow Enhancements

1. **Streamlined Conversation Flow**:
   - Removed rigid conversation phase logic in favor of natural LLM-driven interactions
   - Updated system prompt to encourage suggestions for open-ended requests while directly implementing clear instructions
   - Improved contextual awareness by ensuring the LLM understands the user's intent level
   - Eliminated unnecessary error messages for text-only responses

2. **Design Selection System**:
   - Added ability to select and edit any previous design with a dedicated "Edit This Design" button for each image
   - Implemented a "Start from Scratch" button for returning to the original room image
   - Enhanced user message display with contextual emojis to indicate which image is being edited
     - üìé: Pasted new image
     - üè†: Starting from original room
     - üìå: Editing specific design
     - üîÑ: Continuing with latest design
   - Added visual indicators in the input field when editing specific designs

3. **Context Preservation**:
   - Implemented automatic attachment of the latest modified image with each message
   - Updated system prompt to instruct the LLM to always work with the most recent image
   - Added strict instructions to maintain perspective consistency

4. **UI Simplification**:
   - Removed redundant original image toggle and reset button
   - Simplified image display to a single scrollable container with all versions
   - Improved visual hierarchy with color-coding for different selection buttons
   - Updated welcome message to clarify the suggestion-then-visualization workflow

5. **Error Handling Improvements**:
   - Removed artificial limits on design iterations
   - Eliminated error messages when Gemini doesn't generate expected images
   - Simplified logic to let the LLM naturally decide between text suggestions and visual output